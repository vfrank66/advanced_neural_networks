{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "print(os.listdir(\"../input/training/training\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# these seeds are both required for reproducibility\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dropout, Input\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "92af2b31610a29a30512f165b1c8ca083063da0d"
   },
   "outputs": [],
   "source": [
    "class Configuration:\n",
    "    def __init__(self):\n",
    "        self.feature_extraction_epochs = 10\n",
    "        self.fine_tuning_epochs = 20\n",
    "        self.epochs_without_transfer_learning = 100\n",
    "        self.batch_size = 30\n",
    "        self.data_dir = \"../input/training/training\"\n",
    "        self.val_dir = \"../input/validation/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ea625e695c1e9ceff65cb6614ad5e1e5cb5fdc4"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = Input(shape=(299,299,3), name=\"input\")\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "    #Network Architecture should be\n",
    "   \n",
    "    #Conv2D 128 units, 3x3 kernel, relu activation\n",
    "    #MaxPooling2D 2x2 pool size\n",
    "    conv1 = Conv2D(128, kernel_size=(3,3), activation=\"relu\", name=\"conv_1\")(inputs)\n",
    "    #batch1 = BatchNormalization(name=\"batch_norm_1\")(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), name=\"pool_1\")(conv1)\n",
    "\n",
    "    #Conv2D 64 units, 3x3 kernel, relu activation\n",
    "    #MaxPooling2D 2x2 pool size\n",
    "    conv2 = Conv2D(64, kernel_size=(3,3), activation=\"relu\", name=\"conv_2\")(pool1)\n",
    "    #batch2 = BatchNormalization(name=\"batch_norm_2\")(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), name=\"pool_2\")(conv2)\n",
    "\n",
    "    #Conv2D 32 units, 3x3 kernel, relu activation\n",
    "    #MaxPooling2D 2x2 pool size\n",
    "    conv3 = Conv2D(32, kernel_size=(3,3), activation=\"relu\", name=\"conv_3\")(pool2)\n",
    "    #batch3 = BatchNormalization(name=\"batch_norm_3\")(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), name=\"pool_3\")(conv3)\n",
    "\n",
    "    #Conv2D 16 units, 3x3 kernel, relu activation\n",
    "    #MaxPooling2D 2x2 pool size\n",
    "    conv4 = Conv2D(16, kernel_size=(3,3), activation=\"relu\", name=\"conv_4\")(pool3)\n",
    "    #batch4 = BatchNormalization(name=\"batch_norm_4\")(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), name=\"pool_4\")(conv4)\n",
    "    \n",
    "    # fully connected layers\n",
    "    # output shows \"fc1 (Dense) (None, 1024) 4195328\"\n",
    "    \n",
    "    flatten = Flatten()(pool4)    \n",
    "    fc1 = Dense(1024, activation=\"relu\", name=\"fc1\")(flatten)\n",
    "    \n",
    "    #fc1 = Dense(1024, activation=\"relu\", name=\"fc1\")(pool4)\n",
    "    \n",
    "    #d1 = Dropout(rate=0.2, name=\"dropout1\")(fc1)\n",
    "    #fc2 = Dense(256, activation=\"relu\", name=\"fc2\")(d1)\n",
    "    #d2 = Dropout(rate=0.2, name=\"dropout2\")(fc2)\n",
    "    \n",
    "    #Dense 1024\n",
    "    #Dense softmax layer (named \"output\")\n",
    "    output = Dense(10, activation=\"softmax\", name=\"output\")(fc1)\n",
    "    \n",
    "    \n",
    "\n",
    "    # finalize and compile\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae466d8799754c2cca57d2ab87f5df92eb01439d"
   },
   "outputs": [],
   "source": [
    "def create_callbacks(name):\n",
    "    tensorboard_callback = TensorBoard(log_dir=os.path.join(os.getcwd(), \"tensorboard_log\", name), write_graph=True, write_grads=False)\n",
    "    checkpoint_callback = ModelCheckpoint(filepath=\"./model-weights-\" + name + \".{epoch:02d}-{val_loss:.6f}.hdf5\", monitor='val_loss',\n",
    "                                          verbose=0, save_best_only=True)\n",
    "    return [tensorboard_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f8e2a23a00c70d580924ff6aa0883a13aae38a5"
   },
   "outputs": [],
   "source": [
    "def setup_data(train_data_dir, val_data_dir, img_width=299, img_height=299, batch_size=16):\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        val_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "12cbfe8619b4d51cd04e152ab22d408375978e42"
   },
   "outputs": [],
   "source": [
    "def fit_model(model, train_generator, val_generator, batch_size, epochs, name):\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.n // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.n // batch_size,\n",
    "        callbacks=create_callbacks(name=name),\n",
    "        verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea7aaa8c3d453f20c0d794ac92bfe638b39ad68b"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, val_generator, batch_size):\n",
    "    scores = model.evaluate_generator(val_generator, steps=val_generator.n // batch_size)\n",
    "    print(\"Loss: \" + str(scores[0]) + \" Accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15ba8a607d59569f8089e24551b43859edbf1260"
   },
   "outputs": [],
   "source": [
    "config = Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e66fd618ca1aaeff691f579ce18640413c2a6ea2"
   },
   "outputs": [],
   "source": [
    "train_generator, val_generator = setup_data(config.data_dir, config.val_dir, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8eb2a29fe96abba52c672342664a587063007cdd"
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91a023e4db9754a162be7e512e27124734749884"
   },
   "outputs": [],
   "source": [
    "model = fit_model(model, train_generator, val_generator,\n",
    "                  batch_size=config.batch_size,\n",
    "                  epochs=config.epochs_without_transfer_learning,\n",
    "                  name=\"without_transfer_learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d182784dab10fb89c7d95a5a70989a5ab4e8388"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
